name: vprofile actions
on: workflow_dispatch
env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: vprofileapp
  EKS_CLUSTER: vprofile-eks

jobs:
  Testing:
    runs-on: ubuntu-latest
    steps:

      # Maven
      - name: Code Checkout
        uses: actions/checkout@v4

      - name: Maven test
        run: mvn test

      - name: Checkstyle
        run: mvn checkstyle:checkstyle

      # Setup Java 11 to default (sonar-scanner requirement as of 5.x)
      - name: Setup Java 11
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin' # See 'Supported distros' for available options
          java-version: '11'

      # Setup sonar-scanner
      - name: Setup SonarQube
        uses: warchant/setup-sonar-scanner@v7

      # Run sonar-scanner
      - name: SonarQube Scan
        run: sonar-scanner
           -Dsonar.host.url=${{ secrets.SONAR_URL }}
           -Dsonar.token=${{ secrets.SONAR_TOKEN }}
           -Dsonar.organization=${{ secrets.SONAR_ORGANIZATION }}
           -Dsonar.projectKey=${{ secrets.SONAR_PROJECT_KEY }}
           -Dsonar.sources=src/
           -Dsonar.junit.reportsPath=target/surefire-reports/ 
           -Dsonar.jacoco.reportsPath=target/jacoco.exec 
           -Dsonar.java.checkstyle.reportPaths=target/checkstyle-result.xml
           -Dsonar.java.binaries=target/test-classes/com/visualpathit/account/controllerTest/

      # --- BYPASS QG - NOW ITS PAID OPTION :( ---

      # # Quality Gate status check
      # - name: SonarQube Quality Gate check
      #   id: sonarqube-quality-gate-check
      #   uses: sonarsource/sonarqube-quality-gate-action@master
      #   # Force to fail step after specific time
      #   timeout-minutes: 5
      #   env:
      #     SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
      #   # SONAR_HOST_URL: 

  # Building & Publishing to ECR
  BUILD_AND_PUBLISH:
    needs: Testing
    runs-on: ubuntu-latest
    steps:
      - name: Code Checkout
        uses: actions/checkout@v4
      
      - name: Build & Upload image to ECR
        uses: appleboy/docker-ecr-action@master
        with:
          access_key: ${{ secrets.AWS_ACCESS_KEY_ID }}
          secret_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          registry: ${{ secrets.REGISTRY }}
          repo: ${{ env.ECR_REPOSITORY }}
          region: ${{ env.AWS_REGION }}
          tags: latest,${{ github.run_number }}
          daemon_off: false
          dockerfile: ./Dockerfile
          context: ./

  # EKS Deploy
  DeployToEKS:
    needs: BUILD_AND_PUBLISH
    runs-on: ubuntu-latest
    steps:
      - name: Code checkout
        uses: actions/checkout@v4

      # AWS Credentials
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      # Kubernetes
      - name: Get Kube config file
        run: aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name ${{ env.EKS_CLUSTER }}

      - name: Print config file
        run: cat ~/.kube/config
      
      # ECR Login & Deploy Helm
      - name: Login to ECR
        run: |
          if kubectl get secret regcred >/dev/null 2>&1; then
            echo "Secret 'regcred' already exists. Deleting and recreating it to ensure fresh credentials."
            kubectl delete secret regcred
          fi
          kubectl create secret docker-registry regcred \
            --docker-server=${{ secrets.REGISTRY }} \
            --docker-username=AWS \
            --docker-password=$(aws ecr get-login-password)
          echo "Secret 'regcred' created successfully."


      - name: Deploy Helm
        uses: bitovi/github-actions-deploy-eks-helm@v1.2.8
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
          cluster-name: ${{ env.EKS_CLUSTER }}
          #config-files: .github/values/dev.yaml
          chart-path: helm/vprofilecharts
          namespace: default
          values: appimage=${{ secrets.REGISTRY }}/${{ env.ECR_REPOSITORY }},apptag=${{ github.run_number }}
          name: vprofile-stack

    # Debugging Steps
      - name: Check Pods
        run: kubectl get pods -n default

      - name: Check Services
        run: kubectl get svc -n default

      - name: Check Ingress
        run: kubectl get ingress -n default

      - name: Describe Pods
        run: |
          for pod in $(kubectl get pods -n default -o name); do
            echo "Describing $pod"
            kubectl describe $pod -n default
          done

      - name: Check Pod Logs
        run: |
          for pod in $(kubectl get pods -n default -o name); do
            echo "Logs for $pod"
            kubectl logs $pod -n default
          done

      - name: Describe Services
        run: |
          for svc in $(kubectl get svc -n default -o name); do
            echo "Describing $svc"
            kubectl describe $svc -n default
          done

      - name: Describe Ingress
        run: |
          for ingress in $(kubectl get ingress -n default -o name); do
            echo "Describing $ingress"
            kubectl describe $ingress -n default
          done

      - name: Check Ingress Controller Logs
        run: |
          nginx_pod=$(kubectl get pods -n ingress-nginx -l app.kubernetes.io/component=controller -o name | head -n 1)
          if [ -n "$nginx_pod" ]; then
            echo "Ingress Controller Logs for $nginx_pod"
            kubectl logs $nginx_pod -n ingress-nginx
          else
            echo "No ingress controller pod found in the ingress-nginx namespace."
          fi